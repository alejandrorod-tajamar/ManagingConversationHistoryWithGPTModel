{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing conversation history with the ChatGPT model\n",
    "This sample notebook demonstrates a couple of simple patterns you can use for managing the prompts and conversation history with the ChatGPT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required packages\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if needed, install and/or upgrade to the latest version of the OpenAI Python library\n",
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os module & the OpenAI Python library for calling the OpenAI API\n",
    "# please make sure you have installed required libraries via pip install -r requirements.txt\n",
    "import os, dotenv\n",
    "import openai\n",
    "\n",
    "dotenv.load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the deployment name\n",
    "deployment_name = \"gpt-4o-mini\"\n",
    "\n",
    "# The base URL for your Azure OpenAI resource. e.g. \"https://<your resource name>.openai.azure.com\"\n",
    "# This is the value of the endpoint for your Azure OpenAI resource\n",
    "azure_endpoint = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "\n",
    "# The API key for your Azure OpenAI resource.\n",
    "api_key = os.environ['AZURE_OPENAI_KEY']\n",
    "\n",
    "# Currently OPENAI API have the following versions available: https://learn.microsoft.com/azure/ai-services/openai/reference\n",
    "api_version = \"2024-07-01-preview\"\n",
    "\n",
    "client = openai.AzureOpenAI(\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_key=api_key,\n",
    "    api_version=api_version\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Create the system message for ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant.\n"
     ]
    }
   ],
   "source": [
    "base_system_message = \"You are a helpful assistant.\"\n",
    "\n",
    "system_message = f\"{base_system_message.strip()}\"\n",
    "print(system_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Define helper functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\"):\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += 4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":  # if there's a name, the role is omitted\n",
    "                num_tokens += -1  # role is always required and always 1 token\n",
    "    num_tokens += 2  # every reply is primed with <im_start>assistant\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to send the prompt to the ChatGPT model\n",
    "# More info : https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/chatgpt?pivots=programming-language-chat-completions\n",
    "def send_message(messages, model_name, max_response_tokens=500):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=messages,\n",
    "        max_tokens=max_response_tokens,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Defining a function to print out the conversation in a readable format\n",
    "def print_conversation(messages):\n",
    "    for message in messages:\n",
    "        print(f\"[{message['role'].upper()}]\")\n",
    "        print(message['content'])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Start the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the first user message that will be sent to the model. Feel free to update this.\n",
    "user_message = \"I want to write a blog post about the impact of AI on the future of work.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
    "messages=[{\"role\": \"user\", \"content\": user_message}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 25\n"
     ]
    }
   ],
   "source": [
    "token_count = num_tokens_from_messages(messages)\n",
    "print(f\"Token count: {token_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[USER]\n",
      "I want to write a blog post about the impact of AI on the future of work.\n",
      "\n",
      "[ASSISTANT]\n",
      "### The Impact of AI on the Future of Work: Navigating a New Era\n",
      "\n",
      "As we step further into the 21st century, artificial intelligence (AI) continues to transform every facet of our lives, and the workplace is no exception. From automating repetitive tasks to enhancing decision-making processes, AI is reshaping the traditional work landscape in profound ways. In this blog post, we’ll explore the key areas where AI is making its mark and what the future of work might look like in an\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_response_tokens = 100\n",
    "\n",
    "response = send_message(messages, deployment_name, max_response_tokens)\n",
    "messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "print_conversation(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Continue the conversation\n",
    "\n",
    "When working with the ChatGPT model, it's your responsibity to make sure you stay within the token limits of the model. The model can handle a maximum of 4096 tokens, and this includes the number of tokens in the prompt as well as the `max_tokens` you're requesting from the model. If you exceed these limits, the model will return an error.\n",
    "\n",
    "You should also consider the trade-off between maintaining more of the conversation history and the cost/latency that you'll incur by including those tokens in the prompt. Shorter prompts are cheaper and faster. The amount of the previous conversation you include also makes a difference in how the model responds.\n",
    "\n",
    "In this notebook, we'll show two strategies for managing the conversation history when working with the ChatGPT model.\n",
    "- Option 1: Keep the conversation within a given token limit\n",
    "- Option 2: Keep the conversation within a given number of turns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Keep the conversation within a given token limit\n",
    "\n",
    "`overall_max_tokens` is the maximum number of tokens that you want to include in the prompt. Th maximum number this can be set to is 4096 but you can also consider reducing this number to reduce the cost and latency of the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_max_tokens = 1096\n",
    "prompt_max_tokens = overall_max_tokens - max_response_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can continue the conversation below by editing the user_message and running the cell as many times as you would like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 153\n",
      "[USER]\n",
      "I want to write a blog post about the impact of AI on the future of work.\n",
      "\n",
      "[ASSISTANT]\n",
      "### The Impact of AI on the Future of Work: Navigating a New Era\n",
      "\n",
      "As we step further into the 21st century, artificial intelligence (AI) continues to transform every facet of our lives, and the workplace is no exception. From automating repetitive tasks to enhancing decision-making processes, AI is reshaping the traditional work landscape in profound ways. In this blog post, we’ll explore the key areas where AI is making its mark and what the future of work might look like in an\n",
      "\n",
      "[USER]\n",
      "The target audience for the blog post should be business leaders working in the tech industry.\n",
      "\n",
      "[ASSISTANT]\n",
      "### The Impact of AI on the Future of Work: A Guide for Tech Industry Leaders\n",
      "\n",
      "As business leaders in the tech industry, you are at the forefront of one of the most transformative eras in human history. The integration of artificial intelligence (AI) into the workplace is not just a trend; it’s a seismic shift that is redefining how we conduct business, manage teams, and engage with customers. In this blog post, we will delve into the significant impacts of AI on the future of work\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_message = \"The target audience for the blog post should be business leaders working in the tech industry.\"\n",
    "#user_message = \"Let's talk about generative AI and keep the tone informational but also friendly.\"\n",
    "#user_message = \"Show me a few more examples\"\n",
    "messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "\n",
    "token_count = num_tokens_from_messages(messages)\n",
    "print(f\"Token count: {token_count}\")\n",
    "\n",
    "# remove first message while over the token limit\n",
    "while token_count > prompt_max_tokens:\n",
    "    messages.pop(0)\n",
    "    token_count = num_tokens_from_messages(messages)\n",
    "\n",
    "response = send_message(messages, deployment_name, max_response_tokens)\n",
    "\n",
    "#Append assistance response \n",
    "messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "print_conversation(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Keep the conversation within a given number of turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_messages = 10\n",
    "\n",
    "overall_max_tokens = 4096\n",
    "prompt_max_tokens = overall_max_tokens - max_response_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can continue the conversation below by editing the user_message and running the cell as many times as you would like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[USER]\n",
      "I want to write a blog post about the impact of AI on the future of work.\n",
      "\n",
      "[ASSISTANT]\n",
      "### The Impact of AI on the Future of Work: Navigating a New Era\n",
      "\n",
      "As we step further into the 21st century, artificial intelligence (AI) continues to transform every facet of our lives, and the workplace is no exception. From automating repetitive tasks to enhancing decision-making processes, AI is reshaping the traditional work landscape in profound ways. In this blog post, we’ll explore the key areas where AI is making its mark and what the future of work might look like in an\n",
      "\n",
      "[USER]\n",
      "The target audience for the blog post should be business leaders working in the tech industry.\n",
      "\n",
      "[ASSISTANT]\n",
      "### The Impact of AI on the Future of Work: A Guide for Tech Industry Leaders\n",
      "\n",
      "As business leaders in the tech industry, you are at the forefront of one of the most transformative eras in human history. The integration of artificial intelligence (AI) into the workplace is not just a trend; it’s a seismic shift that is redefining how we conduct business, manage teams, and engage with customers. In this blog post, we will delve into the significant impacts of AI on the future of work\n",
      "\n",
      "[USER]\n",
      "Make the post about generative AI aimed at business leaders who have some knowledge of the technology.\n",
      "\n",
      "[ASSISTANT]\n",
      "### The Transformative Impact of Generative AI on the Future of Work: Insights for Tech Industry Leaders\n",
      "\n",
      "As a business leader in the tech industry, you are undoubtedly aware of the rapid advancements in generative AI technologies and their potential to revolutionize the workplace. Unlike traditional AI, which focuses on data analysis and automation of predefined tasks, generative AI has the ability to create new content, ideas, and solutions, thereby opening up new avenues for innovation and productivity. In this post, we’ll explore\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_message = \"Make the post about generative AI aimed at business leaders who have some knowledge of the technology.\"\n",
    "messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "\n",
    "while len(messages) > max_messages:\n",
    "    messages.pop(0)\n",
    "\n",
    "token_count = num_tokens_from_messages(messages)\n",
    "\n",
    "while token_count > prompt_max_tokens:\n",
    "    # remove first message from messages\n",
    "    messages.pop(0)\n",
    "    token_count = num_tokens_from_messages(messages)\n",
    "\n",
    "response = send_message(messages, deployment_name, max_response_tokens)\n",
    "\n",
    "#Append assistant response\n",
    "messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "print_conversation(messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Modificar el Mensaje del Sistema\n",
    "Enunciado:\n",
    "Crea un mensaje del sistema que defina a ChatGPT como un \"analista financiero experto\". Imprime el mensaje del sistema resultante y utilízalo en un mensaje inicial del usuario que pregunte:\n",
    "\"¿Cuáles son las tendencias actuales en el mercado de acciones tecnológicas?\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a financial analyst expert.\n",
      "[USER]\n",
      "What are the current trends in the tech stock market?\n",
      "\n",
      "[ASSISTANT]\n",
      "As of my last update in October 2021, I can't provide real-time data or current trends in the tech stock market. However, I can give you some general trends that were shaping the tech industry around that time, which may still be relevant:\n",
      "\n",
      "1. **Cloud Computing Growth**: Companies focusing on cloud services, such as Amazon (AWS), Microsoft (Azure), and Google Cloud, were experiencing significant growth as businesses continued to migrate to cloud-based solutions.\n",
      "\n",
      "2. **Artificial Intelligence and Machine\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Mensaje del sistema\n",
    "base_system_message = \"You are a financial analyst expert.\"\n",
    "system_message = f\"{base_system_message.strip()}\"\n",
    "print(system_message)\n",
    "\n",
    "# Crear lista de mensajes\n",
    "user_message = \"What are the current trends in the tech stock market?\"\n",
    "messages = [{\"role\": \"user\", \"content\": user_message}]\n",
    "\n",
    "# Enviar mensaje y recibir respuesta\n",
    "response = send_message(messages, deployment_name, max_response_tokens)\n",
    "\n",
    "messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "print_conversation(messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Contar Tokens en una Conversación Extendida\n",
    "Enunciado:\n",
    "Dado un conjunto inicial de mensajes, agrega tres mensajes adicionales:\n",
    "\n",
    "\"Explain the impact of inflation on stock prices.\"\n",
    "\"What are the top stocks to watch in 2025?\"\n",
    "\"Summarize the latest market news in 50 words.\"\n",
    "Calcula y muestra el número total de tokens tras añadir cada mensaje.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count after adding 'Explain the impact of inflation on stock prices.': 48\n",
      "Token count after adding 'What are the top stocks to watch in 2025?': 65\n",
      "Token count after adding 'Summarize the latest market news in 50 words.': 82\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Mensajes iniciales\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant specialized in financial topics.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What are the current trends in the tech stock market?\"}\n",
    "]\n",
    "\n",
    "# Mensajes adicionales\n",
    "additional_messages = [\n",
    "    \"Explain the impact of inflation on stock prices.\",\n",
    "    \"What are the top stocks to watch in 2025?\",\n",
    "    \"Summarize the latest market news in 50 words.\"\n",
    "]\n",
    "\n",
    "# Agregar mensajes y calcular tokens\n",
    "for msg in additional_messages:\n",
    "    messages.append({\"role\": \"user\", \"content\": msg})\n",
    "    token_count = num_tokens_from_messages(messages)\n",
    "    print(f\"Token count after adding '{msg}': {token_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Personalizar el Mensaje del Sistema Según el Usuario\n",
    "Enunciado:\n",
    "Escribe un programa que permita al usuario definir el rol de ChatGPT mediante una entrada de texto (input). Una vez definido, responde al mensaje:\n",
    "\"What are your key skills as an assistant?\"\n",
    "Usa el mensaje del sistema definido por el usuario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SYSTEM]\n",
      "You are a helpful assistant specialized in fossils.\n",
      "\n",
      "[USER]\n",
      "What are your key skills as an assistant?\n",
      "\n",
      "[ASSISTANT]\n",
      "As an assistant specialized in fossils, my key skills include:\n",
      "\n",
      "1. **Knowledge of Paleontology**: I have a solid understanding of fossil types, formation processes, and the history of life on Earth.\n",
      "\n",
      "2. **Identification and Classification**: I can help identify and classify various fossils based on physical characteristics and geological context.\n",
      "\n",
      "3. **Research Skills**: I can assist in finding and summarizing scientific literature related to fossils, paleoenvironments, and related fields.\n",
      "\n",
      "4. **Educational Support**\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Entrada del usuario para definir el mensaje del sistema\n",
    "user_defined_role = input(\"Define the role of the assistant: \")\n",
    "system_message = f\"You are {user_defined_role.strip()}.\"\n",
    "\n",
    "# Crear lista de mensajes\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": \"What are your key skills as an assistant?\"}\n",
    "]\n",
    "\n",
    "# Enviar mensaje y recibir respuesta\n",
    "response = send_message(messages, deployment_name, max_response_tokens)\n",
    "\n",
    "messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "# Mostrar la conversación\n",
    "print_conversation(messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4: Crear un Generador de Respuestas Creativo\n",
    "Enunciado:\n",
    "Diseña un programa que permita configurar la creatividad del modelo (temperatura) a través de una entrada del usuario. Una vez configurado, responde a la pregunta:\n",
    "\"Can you suggest an out-of-the-box idea for a startup?\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Startup Idea: \"MoodScape\" - Personalized Ambient Environment Service**\n",
      "\n",
      "**Concept:**\n",
      "MoodScape is a subscription-based service that provides personalized ambient environments for homes, offices, and public spaces. Leveraging AI, smart devices, and IoT technology, MoodScape creates tailored atmospheres based on individual preferences, emotional states, or productivity needs.\n",
      "\n",
      "**How It Works:**\n",
      "1. **Personalized Assessment:** Users complete a quick survey or use an app feature to analyze their current mood, desired ambiance, or specific tasks they need to focus on (e.g., relaxation, creativity, or productivity).\n",
      "\n",
      "2. **AI-Powered Environment Design:** The algorithm curates a unique combination of lighting, sound, temperature, and scent profiles. For example:\n",
      "   - **Relaxation Mode:** Soft blue lighting, gentle ocean sounds, and lavender scent.\n",
      "   - **Focus Mode:** Bright white lighting, subtle instrumental music, and eucalyptus scent.\n",
      "   - **Creative Mode:** Warm yellow lighting, nature sounds, and citrus scent.\n",
      "\n",
      "3. **Smart Device Integration:** MoodScape connects with users’ existing smart home devices (like lights, speakers, and scent diffusers) to adjust settings based on the desired environment.\n",
      "\n",
      "4. **Subscription Models:** Users choose between:\n",
      "   - **Basic Plan:** Daily changing themes based on a set schedule (morning, afternoon, evening).\n",
      "   - **Premium Plan:** On-demand adjustments via an app and integration with personal calendars to suggest environments based on scheduled activities.\n",
      "\n",
      "5. **Community Features:** Users can share their favorite ambiance settings within the MoodScape community, allowing for exploration of different themes and inviting collaboration on mood playlists or scent mixes.\n",
      "\n",
      "6. **Corporate Wellness Programs:** Partner with companies to implement MoodScape in workspaces, enhancing employee well-being and productivity through tailored environments.\n",
      "\n",
      "**Market Differentiation:**\n",
      "While there are existing products for lighting and sound, MoodScape integrates all sensory experiences into one cohesive service, enhancing user experience while improving mental health and productivity. It taps into the growing wellness market, focusing on self-care and personalized experiences in homes and workplaces.\n",
      "\n",
      "**Future Expansion:**\n",
      "- A line of MoodScape proprietary scent diffusers or sound systems customized for optimum performance with the service.\n",
      "- Collaborations with wellness coaches and therapists to create environments tailored for meditation or therapy sessions.\n",
      "\n",
      "With focus on innovation and personalized experiences, MoodScape caters to an evolving market that values mental wellness and productivity, making it a compelling startup idea.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Entrada del usuario para definir la creatividad\n",
    "temperature = float(input(\"Set the creativity level (0.0 - 1.0): \"))\n",
    "if not (0.0 <= temperature <= 1.0):\n",
    "    raise ValueError(\"Creativity level must be between 0.0 and 1.0.\")\n",
    "\n",
    "# Crear lista de mensajes\n",
    "system_message = \"You are a highly creative assistant.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": \"Can you suggest an out-of-the-box idea for a startup?\"}\n",
    "]\n",
    "\n",
    "# Enviar mensaje con creatividad ajustada\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    max_tokens=1000,\n",
    "    temperature=temperature\n",
    ")\n",
    "\n",
    "# Mostrar la respuesta\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5: Cambiar el Tono del Mensaje\n",
    "Enunciado:\n",
    "Configura el mensaje del sistema para que ChatGPT responda en un tono humorístico y escribe una respuesta al mensaje:\n",
    "\"Explain quantum computing in a funny way.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SYSTEM]\n",
      "You are a humorous assistant.\n",
      "\n",
      "[USER]\n",
      "Explain quantum computing in a funny way.\n",
      "\n",
      "[ASSISTANT]\n",
      "Alright, imagine you have a really special cat, let’s call him Schrödinger's Cat. Now, Schrödinger's Cat isn’t just any ordinary cat; he’s both alive and dead at the same time! Why? Because he’s stuck in a quantum box, and he refuses to choose a side – it’s a classic case of feline indecision.\n",
      "\n",
      "Now, quantum computing is like having a whole army of Schrödinger's Cats, but instead of just lounging around in boxes, they’re computing things at lightning speed! In the classical world, computers are like really diligent tortoises that can only handle one task at a time. They’re great at following instructions, but if you ask them to multitask, they’ll just stare at you as if you’ve asked them to solve a Rubik’s Cube while riding a unicycle.\n",
      "\n",
      "But quantum computers? They’re like hyperactive rabbits that can simultaneously hop in multiple directions! They use qubits, which are like the magical cat versions of bits. While traditional bits are either 0 or 1 (like choosing between tuna or kibble), qubits can be both at the same time, thanks to a little thing called superposition. It’s like having your cake and eating it too – and then realizing you also have pie, and cake, and ice cream, and somehow it’s all still calorie-free!\n",
      "\n",
      "And let’s not forget entanglement – that’s when qubits become best friends and stay connected no matter how far apart they are, like those friends who claim they’ll always be there for you, even if they move to the other side of the galaxy. So when you make a change to one qubit, its best buddy instantly knows, like they have some sort of quantum telepathy going on. “Hey, I just flipped to 1! You better do the same, buddy!”\n",
      "\n",
      "So, in short, quantum computing is like having a party where every guest is a cat who can be both alive and dead, can teleport messages to each other, and can eat infinite cake without gaining weight. It sounds chaotic, but it’s actually a way to solve problems way faster than any of those slowpoke classical computers could ever dream of! Just remember to keep the boxes closed – we don't want any real cats getting involved!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Mensaje del sistema humorístico\n",
    "system_message = \"You are a humorous assistant.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": \"Explain quantum computing in a funny way.\"}\n",
    "]\n",
    "\n",
    "# Enviar mensaje y recibir respuesta\n",
    "response = send_message(messages, deployment_name, 1000)\n",
    "\n",
    "#append assistant response\n",
    "messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "print_conversation(messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 6: Resumir Mensajes Previos\n",
    "Enunciado:\n",
    "Dado un historial de conversación de 5 mensajes, crea una función que resuma el contenido de los mensajes del usuario en una sola oración.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User messages summary: AI involves the use of machine learning, which employs algorithms to learn from data, including neural networks that simulate human brain functions, and has various applications in fields like image recognition, natural language processing, and autonomous systems.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Historial de mensajes\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about AI.\"},\n",
    "    {\"role\": \"user\", \"content\": \"How does machine learning work?\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you explain neural networks?\"},\n",
    "    {\"role\": \"user\", \"content\": \"What are the applications of deep learning?\"}\n",
    "]\n",
    "\n",
    "# Resumir mensajes del usuario\n",
    "def summarize_user_messages(messages):\n",
    "    user_messages = [msg['content'] for msg in messages if msg['role'] == 'user']\n",
    "    summary_prompt = \"Summarize the following messages into one sentence: \" + \" \".join(user_messages)\n",
    "    summary = send_message([{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                            {\"role\": \"user\", \"content\": summary_prompt}], deployment_name)\n",
    "    return summary\n",
    "\n",
    "# Obtener y mostrar el resumen\n",
    "summary = summarize_user_messages(messages)\n",
    "print(f\"User messages summary: {summary}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 7: Configuración de Temperatura y Tono\n",
    "Enunciado:\n",
    "Escribe un programa que cambie la configuración de temperatura a 0.9 para obtener respuestas más creativas y responde al mensaje:\n",
    "\"Suggest a unique title for a blog about AI in education.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"EduTech Evolution: Navigating the AI Frontier in Learning\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Mensajes iniciales\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a creative assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Suggest a unique title for a blog about AI in education.\"}\n",
    "]\n",
    "\n",
    "# Ajustar temperatura y enviar mensaje\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    max_tokens=1000,\n",
    "    temperature=0.9\n",
    ")\n",
    "\n",
    "# Mostrar la respuesta\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
